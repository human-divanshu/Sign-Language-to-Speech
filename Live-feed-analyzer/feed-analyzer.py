import numpy as np
import cv2
from Tkinter import *
import Image, ImageTk
import copy


# Just a silly counter to keep track of frames being
# generated, it can be used to save frames by giving them
# unique names in serial order. The counter will be increased
# by 1 as new frame will be read from video feed.
frameNumber = 0

# A boolean value tell if the frame is to be saved or not
saveFrame = False


###################################################
#
# processFrame(frame) : function
#
# Gets a frame as input and you need to return two
# frames after processing them. These will be shown 
# in screen2 and screen3 of the GUI window.
# Screen1 shows the live feed by default
#
###################################################

def processFrame(frame):
    global frameNumber
    global saveFrame
    
    # defining the skin color lower and upper threshold
    # using YCbCr color family
    # Read this https://en.wikipedia.org/wiki/YCbCr for more information
    # on color family
    # the following threshold has been generated by taking a picture of face/
    # hands and ploting its colors to find the peak of skin colors
    # 
    # general strategy is to use haar classifier to detect face and then plot 
    # face colors and get lower/upper bound for face's skin colors. This can be
    # used to dynamically configure system to work with any person's skin tone.
    
    min_YCrCb = np.array([0,133,77], np.uint8)
    max_YCrCb = np.array([255,173,127], np.uint8)    
    
    # Create a copy of input frame
    # frame is just an image
    # word frame and image have been used for one-another
    f1 = copy.deepcopy(frame)
    
    # Convert frame to YCrCb
    imageYCrCb = cv2.cvtColor(f1, cv2.COLOR_BGR2YCR_CB)

    # Find region with skin tone in YCrCb image
    skinRegion = cv2.inRange(imageYCrCb, min_YCrCb, max_YCrCb)

    # Do contour detection on skin region
    contours, hierarchy = cv2.findContours(skinRegion, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # Fill the contour on the source image
    # This will convert skin color into black color
    for i, c in enumerate(contours):
        area = cv2.contourArea(c)
        # area can be configured
        if area > 2500:
            cv2.drawContours(f1, contours, i, (0, 0, 0), -1) # -1 fills the countour, else you can give outline thinkness
            
    # create gray scale image 
    gray = cv2.cvtColor(f1, cv2.COLOR_BGR2GRAY)
    # convert black to white and rest to black
    ret, final = cv2.threshold(gray, 5, 255, cv2.THRESH_BINARY_INV)
    
    if saveFrame:
        sFrame = cv2.resize(final, (100, 100)) # resize to 100 x 100 to save
        cv2.imwrite("output/frame-"+str(frameNumber)+".bmp", sFrame)
        frameNumber = frameNumber + 1

    return f1, final

#############################################
#
# processFrame(frame): function ends here
#
#############################################

#####################################################
#
# Main GUI. DO NOT CHNAGE ANYTHING AFTER THIS
#
######################################################

window = Tk()  #Makes main window
window.wm_title("Live Feed Analyzer")
window.config(background="#D9D9D9")
window.attributes('-zoomed', True) # set window to maximum


#Capture video frames
cap = cv2.VideoCapture(0)

# function to show various frames in GUI
def show_frame():
    ret, frame = cap.read()
    
    # original frame resolution will vary according to camera being used.
    # we need to reduce its size in order to process it without much lag
    frame = cv2.resize(frame, (432, 324))
    
    # crop the image to make it square because square image is better for
    # NN inputs
    frame = frame[:,54:378]
    
    # filp the frame to create mirror image effect
    frame = cv2.flip(frame, 1)
    
    # all processing is done here
    f1, f2 = processFrame(frame)
    
    # the rest code in the function is just to display the frames in GUI
    # no need to change
    img1 = Image.fromarray(frame)
    imgtk1 = ImageTk.PhotoImage(image=img1)
    img2 = Image.fromarray(f1)
    imgtk2 = ImageTk.PhotoImage(image=img2)    
    img3 = Image.fromarray(f2)
    imgtk3 = ImageTk.PhotoImage(image=img3)        
    display1.imgtk = imgtk1 # Show the live feed
    display1.configure(image=imgtk1)    
    display2.imgtk = imgtk2 # Show the processed feed
    display2.configure(image=imgtk2)    
    display3.imgtk = imgtk3 # Show the processed feed
    display3.configure(image=imgtk3)
    
    window.after(10, show_frame) 

# Main label
mainLabel = Label(window, text="Live Feed Experimenter\nSend bugs or crash reports to human.divanshu@gmail.com with screenshot")
mainLabel.grid(row=0, column=0, columnspan=6)
Label(window, text="Input Feed").grid(row=1, column=0, columnspan=2, pady=2)
Label(window, text="Hand Detect").grid(row=1, column=2, columnspan=2, pady=2)
Label(window, text="Output Feed").grid(row=1, column=4, columnspan=2, pady=2)

# position the frames in GUI
display1 = Label(window)
display1.grid(row=2, column=0, columnspan=2, pady=2)  # on left side
display2 = Label(window)
display2.grid(row=2, column=2, columnspan=2, pady=2) # on right side
display3 = Label(window)
display3.grid(row=2, column=4, columnspan=2, pady=2) # on right side

show_frame() #Display
window.mainloop()  #Starts GUI
